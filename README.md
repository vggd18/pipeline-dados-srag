# Desafio de Engenharia de Dados - GGMA (Sec. Sa√∫de Recife)

Este reposit√≥rio cont√©m a minha solu√ß√£o para o desafio de Engenharia de Dados da Secretaria de Sa√∫de do Recife. O projeto consiste em um pipeline ETL (Extract, Transform, Load) que processa dados de S√≠ndrome Respirat√≥ria Aguda Grave (SRAG) do OpenDataSUS.

## üöÄ Tecnologias Utilizadas

* **Python 3.10+**
* **Polars:** Para extra√ß√£o e transforma√ß√£o de dados em alta performance.
* **DuckDB:** Como banco de dados SQL anal√≠tico (OLAP) open-source.
* **s3fs:** Para permitir a leitura direta dos arquivos Parquet do bucket S3.

## üèÉ Como Executar o Projeto

1.  Clone este reposit√≥rio:
    ```bash
    git clone [URL-DO-SEU-REPOSIT√ìRIO-GHUB]
    cd [NOME-DO-SEU-REPOSIT√ìRIO]
    ```

2.  Crie um ambiente virtual (recomendado) e instale as depend√™ncias:
    ```bash
    python -m venv venv
    source venv/bin/activate  # No Windows: .\venv\Scripts\activate
    pip install -r requirements.txt
    ```

3.  Execute o pipeline ETL:
    ```bash
    python etl_pipeline.py
    ```

---

## üìã Relat√≥rio do Desafio
Esta se√ß√£o cumpre o requisito de relat√≥rio do processo seletivo.

### 1. Dados

***Descri√ß√£o dos Dados:**
    Os dados escolhidos foram os registros de S√≠ndrome Respirat√≥ria Aguda Grave (SRAG) hospitalizados, disponibilizados pelo Minist√©rio da Sa√∫de atrav√©s do OpenDataSUS. Este conjunto de dados inclui informa√ß√µes demogr√°ficas, sintomas, fatores de risco, dados de vacina√ß√£o (COVID-19 e Influenza), interna√ß√£o, uso de UTI e resultados laboratoriais.

***Fonte(s) de Dados:**
    * **P√°gina de Recurso:** `https://opendatasus.saude.gov.br/dataset/srag-2021-a-2024`
    * **Link Direto (Parquet 2024):** `https://s3.sa-east-1.amazonaws.com/ckan.saude.gov.br/SRAG/2024/INFLUD24-26-06-2025.parquet`
    * **Dicion√°rio de Dados:** `https://opendatasus.saude.gov.br/dataset/39a4995f-4a6e-440f-8c8f-b00c81fae0d0/resource/3135ac9c-2019-4989-a893-2ed50ebd8e68/download/dicionario-de-dados-2019-a-2025.pdf`

***Justificativa da Escolha:**
    Escolhi este dataset por tr√™s motivos:
    1.  **Relev√¢ncia:** Sendo uma vaga para a Secretaria de Sa√∫de do Recife, utilizar dados p√∫blicos de sa√∫de (SRAG/COVID-19) √© diretamente relevante para o dom√≠nio de neg√≥cio da organiza√ß√£o.
    2.  **Riqueza:** O dataset possui 194 colunas, o que permitiu demonstrar uma variedade de t√©cnicas de transforma√ß√£o (tipagem de data, mapeamento de dicion√°rio, sanitiza√ß√£o de strings, tratamento de booleanos).
    3.  **Escopo:** Conforme a orienta√ß√£o do desafio de focar em "qualidade ao inv√©s de quantidade", optei por utilizar apenas os dados de 2024. Este escopo (+260.000 registros) √© robusto o suficiente para provar a efici√™ncia do pipeline, sem adicionar complexidade desnecess√°ria no download de m√∫ltiplos arquivos anuais.

###2. Pipeline (Extra√ß√£o e Transforma√ß√£o)

* **Extra√ß√£o (E):** A extra√ß√£o √© feita em Python usando a biblioteca Polars. O m√©todo `pl.read_parquet()` √© usado para ler o arquivo `.parquet` diretamente do bucket S3 do OpenDataSUS, carregando-o em um DataFrame em mem√≥ria.

* **Transforma√ß√£o (T):** Esta foi a etapa mais complexa, focada em limpeza, normaliza√ß√£o e enriquecimento sem√¢ntico:
    1.  **Renomea√ß√£o:** Todas as colunas foram convertidas para `snake_case` (min√∫sculas) para padroniza√ß√£o.
    2.  **Tipagem Robusta:**
        * **Datas:** Colunas de data (ex: `dt_notific`) foram convertidas de string para `pl.Date`, usando `str.to_datetime(strict=False)` para garantir que formatos mistos (date e datetime) ou nulos n√£o quebrassem o pipeline.
        * **N√∫meros:** Colunas num√©ricas (ex: `nu_idade_n`) foram convertidas para `pl.Int32(strict=False)`.
        * **Identificadores:** Colunas que s√£o c√≥digos (ex: `co_mun_not`, `nu_notific`) foram mantidas como `String` para preservar zeros √† esquerda.
    3.  **Mapeamento Sem√¢ntico (Qualidade):**
        * **Booleanos:** Colunas que usam o padr√£o `1-Sim`, `2-N√£o`, `9-Ignorado` (ex: `febre`, `uti`, `cardiopati`) foram convertidas para o tipo `Boolean` (`True`, `False`, `None`).
        * **Dicion√°rio de Dados:** Colunas categ√≥ricas (ex: `evolucao`, `cs_sexo`) foram mapeadas de seus c√≥digos (ex: `1`, `2`) para valores leg√≠veis (ex: `"Cura"`, `"√ìbito"`), melhorando a legibilidade para o analista.
    4.  **Sanitiza√ß√£o:** Todas as colunas `String` restantes passaram por `.str.strip_chars().str.to_lowercase()` para remover espa√ßos e padronizar o case.
    5.  **Deduplica√ß√£o:** O DataFrame final foi deduplicado pela chave prim√°ria `nu_notific`.
